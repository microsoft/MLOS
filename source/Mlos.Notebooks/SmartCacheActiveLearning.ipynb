{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "The goal of this notebook is to optimize SmartCache using the Active Learning approach.\n",
    "\n",
    "We define active learning as an approach when we execute the following loop:\n",
    "1. Get suggested config from optimizer,\n",
    "2. Apply suggested config to SmartCache,\n",
    "3. Execute a fixed workload,\n",
    "4. Collect the metrics from smart cache,\n",
    "5. Register an observation with the optimizer.\n",
    "\n",
    "This is different from online learning in that the workload is fixed. In an online learning situation the workload could fluctuate, and we would pick up the changing workload signatures. This is more complicated and will be our next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "Lots to do here.\n",
    "<s>\n",
    "1. Configure Workload\n",
    "1. Loop:\n",
    "    1. Configure SmartCache\n",
    "    1. Execute Workload\n",
    "    1. Collect Metrics\n",
    "    1. Register/Suggest\n",
    "\n",
    "We will do it in 2 steps:\n",
    "1. Do it for a fixed workload without passing in any size/frequency estimators.\n",
    "</s>\n",
    "2. Add the estimators (will require upgrading the Optimizer to consume context features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "from subprocess import Popen, CREATE_NEW_CONSOLE\n",
    "import sys\n",
    "\n",
    "import grpc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlos.Grpc.BayesianOptimizerFactory import BayesianOptimizerFactory\n",
    "from mlos.Logger import create_logger\n",
    "\n",
    "from mlos.Examples.SmartCache import HitRateMonitor, SmartCache, SmartCacheWorkloadGenerator, SmartCacheWorkloadLauncher\n",
    "from mlos.Mlos.SDK import MlosExperiment\n",
    "from mlos.Optimizers.OptimizationProblem import OptimizationProblem, Objective\n",
    "from mlos.Spaces import Point, SimpleHypergrid, ContinuousDimension\n",
    "\n",
    "grpc_port = 50051\n",
    "mlos_python_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"Mlos.Python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = create_logger('Optimizing Smart Cache')\n",
    "optimizer_service_grpc_channel = grpc.insecure_channel(f'localhost:{grpc_port}')\n",
    "bayesian_optimizer_factory = BayesianOptimizerFactory(grpc_channel=optimizer_service_grpc_channel, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization Problem\n",
    "#\n",
    "optimization_problem = OptimizationProblem(\n",
    "    parameter_space=SmartCache.parameter_search_space,\n",
    "    objective_space=SimpleHypergrid(name=\"objectives\", dimensions=[ContinuousDimension(name=\"hit_rate\", min=0, max=1)]),\n",
    "    context_space=None,\n",
    "    objectives=[Objective(name=\"hit_rate\", minimize=False)]\n",
    ")\n",
    "optimizer = bayesian_optimizer_factory.create_remote_optimizer(optimization_problem=optimization_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "workload_launcher = SmartCacheWorkloadLauncher(logger=logger)\n",
    "mlos_agent = workload_launcher.mlos_agent\n",
    "\n",
    "# Let's configure the SmartCacheWorkload\n",
    "#\n",
    "mlos_agent.set_configuration(\n",
    "    component_type=SmartCacheWorkloadGenerator,\n",
    "    new_config_values=Point(\n",
    "        workload_type='sequential_key_from_range',\n",
    "        sequential_key_from_range_config=Point(\n",
    "            min=0,\n",
    "            range_width=2048\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now finally we build the experiment.\n",
    "#\n",
    "hit_rate_monitor = HitRateMonitor()\n",
    "smart_cache_experiment = MlosExperiment(\n",
    "    smart_component_types=[SmartCache],\n",
    "    telemetry_aggregators=[hit_rate_monitor]\n",
    ")\n",
    "mlos_agent.start_experiment(smart_cache_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_iterations = 100\n",
    "for i in range(num_iterations):\n",
    "    mlos_agent.set_configuration(component_type=SmartCache, new_config_values=optimizer.suggest())\n",
    "    hit_rate_monitor.reset()\n",
    "    workload_launcher.start_workload(block=True)\n",
    "\n",
    "    current_cache_config = mlos_agent.get_configuration(component_type=SmartCache)\n",
    "    features_df = current_cache_config.to_pandas()\n",
    "    hit_rate = hit_rate_monitor.get_hit_rate()\n",
    "    objectives_df = pd.DataFrame({'hit_rate': [hit_rate]})\n",
    "    optimizer.register(features_df, objectives_df)\n",
    "    logger.info(f\"[{i+1}/{num_iterations}]current_config: {current_cache_config}, hit_rate: {hit_rate}, num_requests: {hit_rate_monitor._num_requests}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rate_monitor._num_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "#\n",
    "mlos_agent.stop_experiment(smart_cache_experiment)\n",
    "mlos_globals.mlos_global_context.stop_clock()\n",
    "mlos_agent.stop_all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
