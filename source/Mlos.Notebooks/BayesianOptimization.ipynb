{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the basic principles of [Bayesian Optimization (BO)](https://en.wikipedia.org/wiki/Bayesian_optimization) and how to use MLOS to perform BO.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "In software performance engineering, the impact different (input) parameters (e.g. buffer size, worker thread count, etc.) can have on the (output) performance of a system for a given workload (input) can be modeled as a multidimensional function - one which we don't know the equation for apriori, but are instead trying to learn through careful sampling of the input space and experimentation (test/benchmark runs) to gather output points.\n",
    "Bayesian optimization is one technique for efficiently selecting the samples in the input space to learn the approximate shape of that function and find its optimum, i.,e. the parameters that lead to the best performance.\n",
    "In this example we use a synthetic (i.e. made-up) function that we can look at directly to stand in for a complex system with unknown characteristics.\n",
    "\n",
    "Bayesian Optimization is a [global optimization](https://en.wikipedia.org/wiki/Global_optimization) strategy, so a way to find the global optimum of a mathematical function that's not necessarily [convex](https://en.wikipedia.org/wiki/Convex_function). BO is a black-box optimization technique, meaning that it requires only function values and no other information like gradients.\n",
    "\n",
    "This is in contrast to other optimization strategies, such as gradient descent or conjugate gradient that require gradients and are only guaranteed to find a local optimum (if the function is assumed to be convex, this is also the global optimum).\n",
    "\n",
    "Finding the global optimum of a general non-convext function is NP-hard, which makes it impossible to provide effective convergence guarantees for any global optimization strategy, including Bayesian Optimization. However, BO has been found to be quite effective in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A synthetic example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a simple synthetic example of a one-dimensional function that we assume is unknown.\n",
    "If we actually had access to the function, we could use more efficient techniques using calculus and would not be using Bayesian Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fake performance function\n",
    "# In an actual application, we would not have access to this function directly.\n",
    "# Instead, we could only measure the outcome by running an experiment, such as timing\n",
    "# a particular run of the system.\n",
    "def f(x):\n",
    "    return (6*x-2)**2*np.sin(12*x-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a real use case for global optimization, the function we want to optimize is usually only implicitly defined and very expensive to compute, such as training and evaluating a neural network, or timing the run of a large workload on a distributed database. Given the cost of evaluating the function, our goal is to find an optimum while keeping the number of function evaluations to a minimum.\n",
    "\n",
    "In this synthetic example, we actually know the function, so we can just plot it for illustration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a domain to evaluate\n",
    "line = np.linspace(0, 1)\n",
    "# evaluate function\n",
    "values = f(line)\n",
    "# plot function\n",
    "plt.plot(line, values)\n",
    "plt.xlabel(\"Input (parameter)\")\n",
    "plt.ylabel(\"Objective (i.e. performance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here is to find the global minimum of this function, assuming that we don't have direct access to the formula (given the formula, we could instead calculate the optimum quite precicely using methods from calculus instead). Usually, the function is too expensive to evaluate in such a manner, in particular in higher-dimensional spaces.\n",
    "\n",
    "Now, we use MLOS to construct an OptimizationProblem object that will encapsulate the function and the input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlos.Optimizers.OptimizationProblem import OptimizationProblem, Objective\n",
    "from mlos.Optimizers.BayesianOptimizer import BayesianOptimizer\n",
    "from mlos.Spaces import SimpleHypergrid, ContinuousDimension\n",
    "\n",
    "# single continuous input dimension between 0 and 1\n",
    "input_space = SimpleHypergrid(name=\"input\", dimensions=[ContinuousDimension(name=\"x\", min=0, max=1)])\n",
    "# define output space, we might not know the exact ranges\n",
    "output_space = SimpleHypergrid(name=\"objective\",\n",
    "                               dimensions=[ContinuousDimension(name=\"function_value\", min=-10, max=10)])\n",
    "\n",
    "# define optimization problem with input and output space and objective\n",
    "optimization_problem = OptimizationProblem(\n",
    "    parameter_space=input_space,\n",
    "    objective_space=output_space,\n",
    "    # we want to minimize the function\n",
    "    objectives=[Objective(name=\"function_value\", minimize=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way Bayesian Optimization (in particular what is known as sequential model-based optimization) works is by iterating the following steps:\n",
    "- Evaluate the function at a candidate point x_i (start with a random point x_0), observe f(x_i).\n",
    "- Build / update a **surrogate model** g_i of the objective function (here a Random Forest) using the pairs x_i, f(x_i) that we observed so far.\n",
    "- Pick the next data point to evaluate based on the updated model g_i using a criterion known as **acquisition function**.\n",
    "\n",
    "The idea is that eventually the surrogate model will provide a good approximation of the objective function, but it will be much faster to evaluate (i.e. by predicting with a Random Forest or Gaussian process or another trained machine learning model, instead of running a complex deployment). The acquisition function serves as a means to trade off exploration vs exploitation in collecting new data for building the surrogate model: it picks points that have a low (close to optimum) value of the surrogate model (and so are expected to have a low value of the actual objective). This is the \"exploitation\" of existing knowledge in the model. On the other hand, it also encourages exploring new areas in which there is a lot of uncertainty in the surrogate model, i.e. where we expect the surrogate model not to be very acurate yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is coordinated by the ``BayesianOptimizer`` object, which we will use to performe Bayesian Optimization with a random forest surrogate model. Details of this particular method can be found in [Hutter et. al. (2011)](https://www.cs.ubc.ca/~hutter/papers/11-LION5-SMAC.pdf). We're first configuring the model to refit after every iteration and use 10 trees for the random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlos.Optimizers.BayesianOptimizer import BayesianOptimizer, BayesianOptimizerConfig\n",
    "from mlos.Optimizers.RegressionModels.HomogeneousRandomForestRegressionModel import HomogeneousRandomForestRegressionModelConfig\n",
    "\n",
    "from mlos.Spaces import Point\n",
    "\n",
    "optimizer_config = BayesianOptimizerConfig.DEFAULT.copy()\n",
    "optimizer_config.experiment_designer_config_fraction_random_suggestions = .1\n",
    "random_forest_config = optimizer_config.homogeneous_random_forest_regression_model_config\n",
    "\n",
    "random_forest_config.decision_tree_regression_model_config.n_new_samples_before_refit = 1\n",
    "random_forest_config.decision_tree_regression_model_config.splitter = 'best'\n",
    "# right now we're sampling without replacement so we need to subsample to make the trees different when using the 'best' splitter\n",
    "random_forest_config.samples_fraction_per_estimator = .9\n",
    "random_forest_config.n_estimators = 10\n",
    "\n",
    "optimizer_config.experiment_designer_config.confidence_bound_utility_function_config.alpha = 0.1\n",
    "\n",
    "optimizer = BayesianOptimizer(optimization_problem, optimizer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the actual optimization which will carry out the steps outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(optimizer):\n",
    "    # suggest new value from optimizer\n",
    "    suggested_value = optimizer.suggest()\n",
    "    input_values_df = suggested_value.to_dataframe()\n",
    "    # suggested value are dictionary-like, keys are input space parameter names\n",
    "    # evaluate target function\n",
    "    target_value = f(suggested_value['x'])\n",
    "    print(suggested_value, target_value)\n",
    "    \n",
    "    # build dataframes to \n",
    "    target_values_df = pd.DataFrame({'function_value': [target_value]})\n",
    "\n",
    "    optimizer.register(input_values_df, target_values_df)\n",
    "\n",
    "# run for some iterations\n",
    "n_iterations = 15\n",
    "for i in range(n_iterations):\n",
    "    run_optimization(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 15 iterations, the model is likely to have captured the general shape, but probably not have found the actual optimum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the surrogate\n",
    "surrogate_predictions = optimizer.predict(pd.DataFrame({'x': line})).get_dataframe()\n",
    "# plot observations\n",
    "feature_values, target_values = optimizer.get_experiment_data()\n",
    "plt.scatter(feature_values, target_values, label='observed points')\n",
    "plt.colorbar()\n",
    "# plot true function (usually unknown)\n",
    "plt.plot(line, values, label='true function')\n",
    "# plot the surrogate\n",
    "std = np.sqrt(surrogate_predictions['predicted_value_variance'])\n",
    "value = surrogate_predictions['predicted_value']\n",
    "plt.plot(line, value, label='surrogate predictions g')\n",
    "plt.fill_between(line, value - std, value + std, alpha=.1)\n",
    "plt.plot(line, -optimizer.experiment_designer.utility_function(pd.DataFrame({'x': line})), ':', label='utility_function')\n",
    "plt.ylabel(\"Objective function f (performance)\")\n",
    "plt.xlabel(\"Input variable\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run more iterations to improve the surrogate model and the optimum that is found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for more iterations\n",
    "n_iterations = 50\n",
    "for i in range(n_iterations):\n",
    "    run_optimization(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the surrogate model and optimization process again. The points are colored according to the iteration number, with dark blue points being early in the process and yellow points being later. You can see that at the end of the optimization, the points start to cluster around the optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the surrogate\n",
    "surrogate_predictions = optimizer.predict(pd.DataFrame({'x': line})).get_dataframe()\n",
    "# plot observations\n",
    "feature_values, target_values = optimizer.get_experiment_data()\n",
    "plt.scatter(feature_values, target_values, label='observed points')\n",
    " \n",
    "# plot true function (usually unknown)\n",
    "plt.plot(line, values, label='true function')\n",
    "# plot the surrogate\n",
    "std = np.sqrt(surrogate_predictions['predicted_value_variance'])\n",
    "value = surrogate_predictions['predicted_value']\n",
    "plt.plot(line, value, label='surrogate predictions g')\n",
    "plt.fill_between(line, value - std, value + std, alpha=.1)\n",
    "\n",
    "plt.plot(line, -optimizer.experiment_designer.utility_function(pd.DataFrame({'x': line})), ':', label='utility_function')\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel(\"Objective function f\")\n",
    "ax.set_xlabel(\"Input variable\")\n",
    "bins_axes = ax.twinx()\n",
    "bins_axes.set_ylabel(\"Points sampled\")\n",
    "optimizer._feature_values_df.hist(bins=20, ax=bins_axes, alpha=.3, color='k', label=\"count of querry points\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going further:\n",
    "\n",
    "1) Plot the optimum as a function of iterations. How long does it take for the optimization to converge? Is that stable over several random restarts?\n",
    "\n",
    "2) Does changing the search to a purely random search (setting ``optimizer_config.experiment_designer_config_fraction_random_suggestions = 1``) change how long the optimization takes to find the optimum?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlos]",
   "language": "python",
   "name": "conda-env-mlos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
