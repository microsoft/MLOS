// Global parameters for the experiment.
{
    "experiment_id": "TEST-LOCAL-001",

    // Add your parameters here. Remember to declare them in the
    // experiments' configs in "const_args" and/or "required_args" or
    // in the Service or Optimizer "config" section.

    // This parameter gets propagated into the optimizer config.
    // By default, MLOS expects the benchmark to produce a single
    // scalar, "score".
    "optimization_targets": {
        "score": "min",         // Same as `total_time`, we need it for unit tests.
        "total_time": "min",
        "throughput": "max"
    },

    // Another parameter that gets propagated into the optimizer config.
    // Each such parameter can be overridden by the CLI option, e.g.,
    // `--max_suggestions 20`
    // Number of configurations to be suggested by the optimizer,
    // if optimization is enabled.
    "max_suggestions": 10
}
